# 생선 분류
1. - 생선의 길이와 무게가 주어진다. 도미 35개, 빙어 14개의 데이터를 합친 상태다. 이 데이터를 이용해서 어떤 특정 샘플이 도미인지 빙어인지 분류하는 프로그램을 만들려 한다.[30, 600] 의 샘플을 예측하는 머신러닝 프로그램을 만든다.
   
   - 추가적으로 K-NN 참고 데이터를 5에서 35로 설정하고, 훈련데이터와 타깃데이터의 저장 장소를 찾아본다. 

   - 산점도 그래프로 나타내본다.

<br><br>
[최종] <br>

2. - Numpy 배열을 이용해서 손쉽게 코드를 구현한다. <br>
이후, [25, 150] 샘플을 예측해보고 어떻게 분류의 원리를 이해한다. <br>
마지막으로, 데이터 전처리 과정을 통해 완벽한 생선분류 프로그램을 만든다.

    - 마지막은 산점도로 나타낸다.


<br><br><br>
주어지는 데이터

```
fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0,
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0,
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8,
                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]


fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0,
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0,
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7,
                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]
```

<br><br>

<br>

### 정답 코드 
***
<br>

```py
# 1

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt

# 생선 데이터
fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0,
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0,
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8,
                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]

fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0,
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0,
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7,
                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]

# 2차원 리스트화
fish_data = [[l, w] for l, w in zip(fish_length, fish_weight)]
fish_target = [1] * 35 + [0] * 14

# 넘파이 배열화
fish_arr = np.array(fish_data)
fish_target = np.array(fish_target)

# 인덱스 섞기
np.random.seed(42)
index = np.arange(49)
np.random.shuffle(index)

# 물고기 데이터를 넘파이 배열로 만든 것은 배열 인덱싱을 사용하기 위함이다.
train_data = fish_arr[index[:35]]
train_target = fish_target[index[:35]]
test_data = fish_arr[index[35:]]
test_target = fish_target[index[35:]]

# ML 프로그램
kn = KNeighborsClassifier()
kn.fit(train_data, train_target)
print(kn.score(test_data, test_target))

#[30, 600] 샘플을 예측 / 산점도로 나타내보기
print(kn.predict([[30 ,600]]))

distances, indexes = kn.kneighbors([[30, 600]])
plt.scatter(train_data[:, 0], train_data[:, 1])
plt.scatter(30, 600, marker='^')
plt.scatter(train_data[indexes, 0], train_data[indexes, 1])
plt.xlabel("length")
plt.ylabel("weight")
plt.show()

# K-NN 참고 데이터 14 설정 시 정확도 측정
knr = KNeighborsClassifier(n_neighbors=35)
knr.fit(train_data, train_target)
print(knr.score(test_data, test_target))
```
<br><br>

```py
#2

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

#생선 데이터
fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0,
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0,
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8,
                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]


fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0,
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0,
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7,
                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]


# 생선 데이터 넘파이 배열화
fish_arr = np.column_stack(((fish_length, fish_weight)))

# 타깃 데이터 넘파이 배열화
fish_target = np.concatenate((np.ones(35), np.zeros(14)))


#훈련 데이터와 타깃 데이터 만들기 
#stratify 매개변수에 타깃 데이터를 전달하면 클래스 비율에 맞게 데이터를 나눈다.
train_input, test_input, train_target, test_target = train_test_split(fish_arr, fish_target, stratify=fish_target, random_state=42)

#머신러닝 프로그램
kn = KNeighborsClassifier()
kn.fit(train_input, train_target)
print("빙어로 예측합니다 ->", kn.predict([[25, 150]]))     #25, 150 도미를 빙어로 예측함.


#[25, 150] 을 빙어로 예측한 이유 분석
distances, indexes = kn.kneighbors([[25, 150]])
plt.scatter(train_input[:, 0], train_input[:, 1])
plt.scatter(25, 150, marker='^')
plt.scatter(train_input[indexes, 0], train_input[indexes, 1])
plt.xlabel("length")
plt.ylabel("weight")
plt.show()

print("샘플로부터 가장 가까운 순서대로 거리 길이 :", distances)

plt.scatter(train_input[:, 0], train_input[:, 1])
plt.scatter(25, 150, marker='^')
plt.scatter(train_input[indexes, 0], train_input[indexes, 1])
plt.xlabel("length")
plt.ylabel("weight")
plt.xlim((0, 1000))
plt.show()


#데이터 전처리
mean = np.mean(train_input, axis=0)
std = np.std(train_input, axis=0)

train_scaled = (train_input - mean) / std        #z 점수
kn.fit(train_scaled, train_target)

#결과
test_scaled = (test_input - mean) / std
print("데이터 전처리 후 정확도 :", kn.score(test_scaled, test_target))
print("도미로 예측합니다 ->", kn.predict([[25, 150]]))


#산점도 그래프
new_sample = ([25, 150] - mean) / std
distances, indexes = kn.kneighbors([new_sample])
plt.scatter(train_scaled[:, 0], train_scaled[:, 1])
plt.scatter(new_sample[0], new_sample[1], marker='^')
plt.scatter(train_scaled[indexes, 0], train_scaled[indexes, 1])
plt.xlabel("length")
plt.ylabel("weight")
plt.show()
```

<br><Br><br>

# 생선 무게 예측 (회귀)

1. - '농어의 길이' 특성을 이용해 무게를 예측하는 프로그램을 만들고자 한다.  

    - 농어의 길이와 무게 데이터를 이용해서 산점도 그래프를 그린 후 머신러닝 프로그램을 만들어 보자.

    - 과대적합 혹은 과소적합이 나온다면 이를 해결해보자.


<br>

2. - [1] 과 같은 프로그램에서 50cm 농어의 무게를 예측해본다.
   
   - 50cm 농어의 이웃 샘플을 구하고 산점도로 훈련 데이터에서 이웃 샘플과 50cm 농어 샘플을 나타낸다.

   - 농어의 길이, 무게 데이터를 새로 추가하는 방법 말고 선형 회귀 알고리즘을 사용해서 정확한 값을 예측해보자.<br>
    <직선의 방정식>

   - 문제점 분석해보기

   - 다항 회귀 사용하기

<br><Br><br>



### 정답 코드 
***
<br>

```py
#1

import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split

# 농어의 길이와 무게 데이터
perch_length = np.array([8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0,
       21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7,
       23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5,
       27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0,
       39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5,
       44.0])
perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,
       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,
       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,
       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,
       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,
       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0])


# 산점도 그래프
plt.scatter(perch_length, perch_weight)
plt.xlabel("length")
plt.ylabel("weight")
plt.show()

# 훈련 세트, 테스트 세트 제작
train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state=42)

# 훈련 입력 데이터, 테스트 입력 데이터 2차원 배열화
train_input = train_input.reshape(42,1) 
test_input = test_input.reshape(-1, 1)

# 머신러닝 프로그램 v1
knr = KNeighborsRegressor()
knr.fit(train_input, train_target)
print(knr.score(test_input, test_target))


#과대적합, 과소적합 확인
print(knr.score(train_input, train_target))
print(knr.score(test_input, test_target))   #훈련 세트가 테스트 세트보다 점수가 낮다 = 과소적합 -> 모델을 복잡하게 만든다


# 과소적합 해결하기
knr.n_neighbors = 3
knr.fit(train_input, train_target)

print(knr.score(train_input, train_target))
print(knr.score(test_input, test_target))
```
> [실행]<br>
> 0.9804899950518966<br>
0.9746459963987609

<br><br>

```py
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split


perch_length = np.array([8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0,
       21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7,
       23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5,
       27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0,
       39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5,
       44.0])
perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,
       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,
       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,
       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,
       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,
       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0])

train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state=42)

train_input = train_input.reshape(-1, 1)
test_input = test_input.reshape(-1, 1)

knr = KNeighborsRegressor(n_neighbors=3)
knr.fit(train_input, train_target)
print(knr.score(test_input, test_target))



# 50cm 농어를 예측하고 산점도로 나타내보기
print(knr.predict([[50]]))

distances, indexes = knr.kneighbors([[50]])
plt.scatter(train_input, train_target)
plt.scatter(50, 1033.33333333, marker='^')
plt.scatter(train_input[indexes], train_target[indexes], marker="D")
plt.xlabel("length")
plt.ylabel("weight")
plt.show()


# 100cm 농어 무게 예측해보기
distances, indexes = knr.kneighbors([[100]])
print(np.mean(train_target[indexes]))       # print(knr.predict([[100]])) 


# 선형 회귀 
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(train_input, train_target)

print(lr.predict([[50]]))
print(lr.coef_, lr.intercept_)  #coef_ = 기울기, intercept = y절편


# 산점도 그래프 그리기
plt.scatter(train_input, train_target)
#15~50 까지 일차방정식 그래프를 그림
plt.plot([15, 50], [lr.coef_ * 15 + lr.intercept_, lr.coef_ * 50 + lr.intercept_])

plt.scatter(50, 1241.83860323, marker='^')
plt.xlabel("length")
plt.ylabel("weight")
plt.show()


# 최적의 직선이 아닌 최적의 곡선(2차함수) 찾기

#2차 방정식 그래프를 그리기 위해 길이를 제곱한 항을 훈련 세트에 추가
train_poly = np.column_stack((train_input**2, train_input)) 
test_poly = np.column_stack((test_input**2, test_input))

#모델 훈련
lr = LinearRegression()
lr.fit(train_poly, train_target)

print(lr.predict([[50**2, 50]]))

#산점도로 나타내기
print(lr.coef_, lr.intercept_)

point = np.arange(15, 50 + 1)
plt.scatter(train_input, train_target)
plt.plot(point, 1.01*point**2 + -21*point + 116)
plt.scatter(50, 1573, marker='^')
plt.show()


# 점수 확인하기
print(lr.score(train_poly, train_target))
print(lr.score(test_poly, test_target))
```



